{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe37963-1af6-44fc-a841-8e462443f5e6",
   "metadata": {},
   "source": [
    "## NCCN Guideline Chat Query Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06b38ad1-d90d-4808-99b8-d4c513d7a807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting duckduckgo-search\n",
      "  Downloading duckduckgo_search-7.5.5-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: click>=8.1.8 in /Users/gwt13/Library/Python/3.9/lib/python/site-packages (from duckduckgo-search) (8.1.8)\n",
      "Collecting primp>=0.14.0 (from duckduckgo-search)\n",
      "  Downloading primp-0.14.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting lxml>=5.3.0 (from duckduckgo-search)\n",
      "  Downloading lxml-5.3.1-cp39-cp39-macosx_10_9_universal2.whl.metadata (3.7 kB)\n",
      "Downloading duckduckgo_search-7.5.5-py3-none-any.whl (20 kB)\n",
      "Downloading lxml-5.3.1-cp39-cp39-macosx_10_9_universal2.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading primp-0.14.0-cp38-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: primp, lxml, duckduckgo-search\n",
      "Successfully installed duckduckgo-search-7.5.5 lxml-5.3.1 primp-0.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#!pip install PyPDF\n",
    "#!pip install pdfplumber\n",
    "#%pip install langchain\n",
    "#%pip install langchain-community\n",
    "#%pip install langchain-openai\n",
    "#%pip install langchain-chroma\n",
    "#%pip install fastapi\n",
    "#%pip install pypdf\n",
    "#%pip install gradio\n",
    "#%pip install dotenv\n",
    "%pip install -U duckduckgo-search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8ff95c-0e6e-4da6-9c14-430bfdc65528",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba2779af-84ef-4227-9e9e-6eaf0df87e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import langchain\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "#import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader, PDFPlumberLoader, UnstructuredPDFLoader, PDFMinerLoader\n",
    "from pypdf.errors import PdfReadError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b1b8f5-bfde-4da4-a888-be84fef17484",
   "metadata": {},
   "source": [
    "### Load the API keys for OpenAI and HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "802137aa-8a74-45e0-a487-d1974927d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path=\"keys.env\")\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5499950-efe2-48f2-970c-a17182a24362",
   "metadata": {},
   "source": [
    "### Define the OpenAI LLM that will be used.  Set the name of the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58c85082-e417-4708-9efe-81a5d55d1424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a low cost model from OpenAI will be sufficient\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"nccn_guidelines_db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd8b1ad-0eb9-4918-9322-4374133fa512",
   "metadata": {},
   "source": [
    "### Load in the PDF documents from the NCCN folder. A variety of PDF loaders will stand ready if there is a problem with one of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "730711a9-6ffe-4eee-8f48-d6cfb7314905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success with PyPDFLoader for NCCN/cml2025.pdf\n",
      "Success with PyPDFLoader for NCCN/anal2025.pdf\n",
      "Success with PyPDFLoader for NCCN/biliary2025.pdf\n",
      "Success with PyPDFLoader for NCCN/myeloma2025.pdf\n",
      "Success with PyPDFLoader for NCCN/cervical2025.pdf\n",
      "Success with PyPDFLoader for NCCN/uveal2025.pdf\n",
      "Success with PyPDFLoader for NCCN/gist2025.pdf\n",
      "Success with PyPDFLoader for NCCN/mpn2025.pdf\n",
      "Success with PyPDFLoader for NCCN/cll_sll2025.pdf\n",
      "Success with PyPDFLoader for NCCN/mds2025.pdf\n",
      "Success with PyPDFLoader for NCCN/ovarian2025.pdf\n",
      "Success with PyPDFLoader for NCCN/hcc2025.pdf\n",
      "Success with PyPDFLoader for NCCN/neuroendocrine2025.pdf\n",
      "Success with PyPDFLoader for NCCN/squamous2025.pdf\n",
      "Success with PyPDFLoader for NCCN/colon2025.pdf\n",
      "Success with PyPDFLoader for NCCN/thyroid2025.pdf\n",
      "Success with PyPDFLoader for NCCN/small_bowel2024.pdf\n",
      "Success with PyPDFLoader for NCCN/uterine2025.pdf\n",
      "Success with PyPDFLoader for NCCN/kaposi2025.pdf\n",
      "Success with PyPDFLoader for NCCN/sclc2025.pdf\n",
      "Success with PyPDFLoader for NCCN/bladder2025.pdf\n",
      "Success with PyPDFLoader for NCCN/bone2025.pdf\n",
      "Success with PyPDFLoader for NCCN/nsclc2025.pdf\n",
      "Success with PyPDFLoader for NCCN/vaginal2025.pdf\n",
      "Success with PyPDFLoader for NCCN/esophageal2025.pdf\n",
      "Success with PyPDFLoader for NCCN/NHL_B-cell2025.pdf\n",
      "Success with PyPDFLoader for NCCN/cutaneous_melanoma2025.pdf\n",
      "Success with PyPDFLoader for NCCN/sarcoma2025.pdf\n",
      "Success with PyPDFLoader for NCCN/kidney2025.pdf\n",
      "Success with PyPDFLoader for NCCN/all2024.pdf\n",
      "Success with PyPDFLoader for NCCN/head-and-neck2025.pdf\n",
      "Success with PyPDFLoader for NCCN/aml2025.pdf\n",
      "Success with PyPDFLoader for NCCN/vulvar2024.pdf\n",
      "Success with PyPDFLoader for NCCN/gtn2025.pdf\n",
      "Success with PyPDFLoader for NCCN/waldenstroms2025.pdf\n",
      "Success with PyPDFLoader for NCCN/rectal2025.pdf\n",
      "Success with PyPDFLoader for NCCN/mcc2025.pdf\n",
      "Success with PyPDFLoader for NCCN/prostate2025.pdf\n",
      "Success with PyPDFLoader for NCCN/testicular2025.pdf\n",
      "Success with PyPDFLoader for NCCN/thymic2025.pdf\n",
      "Success with PyPDFLoader for NCCN/basal2025.pdf\n",
      "Success with PyPDFLoader for NCCN/breast2025.pdf\n",
      "Success with PyPDFLoader for NCCN/hodgkins2025.pdf\n",
      "Success with PyPDFLoader for NCCN/NHL_T-cell2025.pdf\n",
      "Success with PyPDFLoader for NCCN/histiocytic_neoplasms2025.pdf\n",
      "Success with PyPDFLoader for NCCN/pancreatic2025.pdf\n",
      "Success with PyPDFLoader for NCCN/ampullary2025.pdf\n",
      "Success with PyPDFLoader for NCCN/gastric2025.pdf\n",
      "Success with PyPDFLoader for NCCN/occult2025.pdf\n",
      "Success with PyPDFLoader for NCCN/cns2025.pdf\n",
      "PDF ingestion completed.\n"
     ]
    }
   ],
   "source": [
    "# Read in documents\n",
    "\n",
    "folder = \"NCCN\"  # Your folder containing PDFs\n",
    "\n",
    "pdf_files = [f for f in os.listdir(folder) if f.endswith('.pdf')]\n",
    "\n",
    "def add_metadata(doc, doc_type):\n",
    "    doc.metadata[\"doc_type\"] = doc_type\n",
    "    return doc\n",
    "\n",
    "# With thanks to CG and Jon R, students on the course, for this fix needed for some users \n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "# If that doesn't work, some Windows users might need to uncomment the next line instead\n",
    "# text_loader_kwargs={'autodetect_encoding': True}\n",
    "\n",
    "def try_multiple_loaders(file_path):\n",
    "    loaders = [\n",
    "        (PyPDFLoader, \"PyPDFLoader\"),\n",
    "        (PDFPlumberLoader, \"PDFPlumberLoader\"),\n",
    "        (UnstructuredPDFLoader, \"UnstructuredPDFLoader\"),\n",
    "        (PDFMinerLoader, \"PDFMinerLoader\")\n",
    "    ]\n",
    "    \n",
    "    for LoaderClass, loader_name in loaders:\n",
    "        try:\n",
    "            loader = LoaderClass(file_path)\n",
    "            docs = loader.load()\n",
    "            print(f\"Success with {loader_name} for {file_path}\")\n",
    "            return docs\n",
    "        except Exception as e:\n",
    "            print(f\"{loader_name} failed: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return None  # If all loaders fail\n",
    "    \n",
    "\n",
    "documents = []\n",
    "for pdf_file in pdf_files:\n",
    "    full_path = os.path.join(folder, pdf_file)\n",
    "    docs = try_multiple_loaders(full_path)\n",
    "    if docs:\n",
    "        doc_type = pdf_file  # or pdf_file.replace('.pdf', '') if you don't want the extension\n",
    "        documents.extend([add_metadata(doc, doc_type) for doc in docs])\n",
    "    else:\n",
    "        print(f\"All loaders failed for {pdf_file}\")\n",
    "\n",
    "print (\"PDF ingestion completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cf82f7-7801-4dcc-9789-db80d0d8f222",
   "metadata": {},
   "source": [
    "### Here is where we define the chunk size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69a6ea82-e182-455c-9ed1-c33f93e66f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=60, separators=[\"\\n\\n\", \"\\n\", \".\", \", \"])\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3302552-b3c5-4f7e-9e25-c6c7a380d7e3",
   "metadata": {},
   "source": [
    "### Looks at the \"doc_type' of the metadata and identifies document types, such as PDF (or TXT). If PDF files were in the input stack, then one should see PDF files. This is quality control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c4f700b-52de-421e-a863-540795248a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document types found: basal2025.pdf, anal2025.pdf, bladder2025.pdf, histiocytic_neoplasms2025.pdf, cml2025.pdf, esophageal2025.pdf, aml2025.pdf, cervical2025.pdf, small_bowel2024.pdf, colon2025.pdf, all2024.pdf, cns2025.pdf, mcc2025.pdf, NHL_B-cell2025.pdf, vulvar2024.pdf, pancreatic2025.pdf, gastric2025.pdf, kidney2025.pdf, prostate2025.pdf, cll_sll2025.pdf, bone2025.pdf, uterine2025.pdf, gist2025.pdf, gtn2025.pdf, head-and-neck2025.pdf, kaposi2025.pdf, rectal2025.pdf, ovarian2025.pdf, squamous2025.pdf, neuroendocrine2025.pdf, mds2025.pdf, ampullary2025.pdf, uveal2025.pdf, sarcoma2025.pdf, breast2025.pdf, biliary2025.pdf, hodgkins2025.pdf, NHL_T-cell2025.pdf, mpn2025.pdf, occult2025.pdf, thyroid2025.pdf, nsclc2025.pdf, hcc2025.pdf, waldenstroms2025.pdf, myeloma2025.pdf, sclc2025.pdf, testicular2025.pdf, thymic2025.pdf, cutaneous_melanoma2025.pdf, vaginal2025.pdf\n"
     ]
    }
   ],
   "source": [
    "doc_types = set(chunk.metadata['doc_type'] for chunk in chunks)\n",
    "print(f\"Document types found: {', '.join(doc_types)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e1851b-e327-4f60-9688-3ed5a8c0d25d",
   "metadata": {},
   "source": [
    "### This code displays unique filenames instead of document types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d662396-ad58-45c9-ac3b-c830adda05c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files processed: basal2025.pdf, anal2025.pdf, bladder2025.pdf, histiocytic_neoplasms2025.pdf, cml2025.pdf, esophageal2025.pdf, aml2025.pdf, cervical2025.pdf, small_bowel2024.pdf, colon2025.pdf, all2024.pdf, cns2025.pdf, mcc2025.pdf, NHL_B-cell2025.pdf, vulvar2024.pdf, pancreatic2025.pdf, gastric2025.pdf, kidney2025.pdf, prostate2025.pdf, cll_sll2025.pdf, bone2025.pdf, uterine2025.pdf, gist2025.pdf, gtn2025.pdf, head-and-neck2025.pdf, kaposi2025.pdf, rectal2025.pdf, ovarian2025.pdf, squamous2025.pdf, neuroendocrine2025.pdf, mds2025.pdf, ampullary2025.pdf, uveal2025.pdf, sarcoma2025.pdf, breast2025.pdf, biliary2025.pdf, hodgkins2025.pdf, NHL_T-cell2025.pdf, mpn2025.pdf, occult2025.pdf, thyroid2025.pdf, nsclc2025.pdf, hcc2025.pdf, waldenstroms2025.pdf, myeloma2025.pdf, sclc2025.pdf, testicular2025.pdf, thymic2025.pdf, cutaneous_melanoma2025.pdf, vaginal2025.pdf\n",
      "Total unique files: 50\n"
     ]
    }
   ],
   "source": [
    "unique_files = set(chunk.metadata['doc_type'] for chunk in chunks)\n",
    "print(f\"Files processed: {', '.join(unique_files)}\")\n",
    "print(f\"Total unique files: {len(unique_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a517df-6919-4932-becf-62a117eb38ec",
   "metadata": {},
   "source": [
    "### A more comprehensive summary of the loading and chunking of the files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58e514f0-9c49-4f53-8fd3-79b29064f8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PDFs found: 50\n",
      "PDF files: cml2025.pdf, anal2025.pdf, biliary2025.pdf, myeloma2025.pdf, cervical2025.pdf, uveal2025.pdf, gist2025.pdf, mpn2025.pdf, cll_sll2025.pdf, mds2025.pdf, ovarian2025.pdf, hcc2025.pdf, neuroendocrine2025.pdf, squamous2025.pdf, colon2025.pdf, thyroid2025.pdf, small_bowel2024.pdf, uterine2025.pdf, kaposi2025.pdf, sclc2025.pdf, bladder2025.pdf, bone2025.pdf, nsclc2025.pdf, vaginal2025.pdf, esophageal2025.pdf, NHL_B-cell2025.pdf, cutaneous_melanoma2025.pdf, sarcoma2025.pdf, kidney2025.pdf, all2024.pdf, head-and-neck2025.pdf, aml2025.pdf, vulvar2024.pdf, gtn2025.pdf, waldenstroms2025.pdf, rectal2025.pdf, mcc2025.pdf, prostate2025.pdf, testicular2025.pdf, thymic2025.pdf, basal2025.pdf, breast2025.pdf, hodgkins2025.pdf, NHL_T-cell2025.pdf, histiocytic_neoplasms2025.pdf, pancreatic2025.pdf, ampullary2025.pdf, gastric2025.pdf, occult2025.pdf, cns2025.pdf\n",
      "\n",
      "Successfully processed documents: 50\n",
      "Sources: NCCN/biliary2025.pdf, NCCN/mpn2025.pdf, NCCN/nsclc2025.pdf, NCCN/sarcoma2025.pdf, NCCN/gist2025.pdf, NCCN/testicular2025.pdf, NCCN/thymic2025.pdf, NCCN/myeloma2025.pdf, NCCN/anal2025.pdf, NCCN/pancreatic2025.pdf, NCCN/mds2025.pdf, NCCN/ovarian2025.pdf, NCCN/basal2025.pdf, NCCN/ampullary2025.pdf, NCCN/uterine2025.pdf, NCCN/hodgkins2025.pdf, NCCN/head-and-neck2025.pdf, NCCN/rectal2025.pdf, NCCN/colon2025.pdf, NCCN/thyroid2025.pdf, NCCN/NHL_T-cell2025.pdf, NCCN/small_bowel2024.pdf, NCCN/vulvar2024.pdf, NCCN/bladder2025.pdf, NCCN/cervical2025.pdf, NCCN/cml2025.pdf, NCCN/esophageal2025.pdf, NCCN/aml2025.pdf, NCCN/prostate2025.pdf, NCCN/vaginal2025.pdf, NCCN/NHL_B-cell2025.pdf, NCCN/waldenstroms2025.pdf, NCCN/mcc2025.pdf, NCCN/breast2025.pdf, NCCN/bone2025.pdf, NCCN/cll_sll2025.pdf, NCCN/squamous2025.pdf, NCCN/sclc2025.pdf, NCCN/kidney2025.pdf, NCCN/kaposi2025.pdf, NCCN/cns2025.pdf, NCCN/histiocytic_neoplasms2025.pdf, NCCN/neuroendocrine2025.pdf, NCCN/occult2025.pdf, NCCN/all2024.pdf, NCCN/gastric2025.pdf, NCCN/gtn2025.pdf, NCCN/hcc2025.pdf, NCCN/cutaneous_melanoma2025.pdf, NCCN/uveal2025.pdf\n",
      "\n",
      "Documents that were chunked: 50\n",
      "Chunked sources: NCCN/biliary2025.pdf, NCCN/mpn2025.pdf, NCCN/nsclc2025.pdf, NCCN/sarcoma2025.pdf, NCCN/gist2025.pdf, NCCN/testicular2025.pdf, NCCN/thymic2025.pdf, NCCN/myeloma2025.pdf, NCCN/anal2025.pdf, NCCN/pancreatic2025.pdf, NCCN/mds2025.pdf, NCCN/ovarian2025.pdf, NCCN/basal2025.pdf, NCCN/ampullary2025.pdf, NCCN/uterine2025.pdf, NCCN/hodgkins2025.pdf, NCCN/head-and-neck2025.pdf, NCCN/rectal2025.pdf, NCCN/colon2025.pdf, NCCN/thyroid2025.pdf, NCCN/NHL_T-cell2025.pdf, NCCN/small_bowel2024.pdf, NCCN/vulvar2024.pdf, NCCN/bladder2025.pdf, NCCN/cervical2025.pdf, NCCN/cml2025.pdf, NCCN/esophageal2025.pdf, NCCN/aml2025.pdf, NCCN/prostate2025.pdf, NCCN/vaginal2025.pdf, NCCN/NHL_B-cell2025.pdf, NCCN/waldenstroms2025.pdf, NCCN/mcc2025.pdf, NCCN/breast2025.pdf, NCCN/bone2025.pdf, NCCN/cll_sll2025.pdf, NCCN/squamous2025.pdf, NCCN/sclc2025.pdf, NCCN/kidney2025.pdf, NCCN/kaposi2025.pdf, NCCN/cns2025.pdf, NCCN/histiocytic_neoplasms2025.pdf, NCCN/neuroendocrine2025.pdf, NCCN/occult2025.pdf, NCCN/all2024.pdf, NCCN/gastric2025.pdf, NCCN/gtn2025.pdf, NCCN/hcc2025.pdf, NCCN/cutaneous_melanoma2025.pdf, NCCN/uveal2025.pdf\n",
      "\n",
      "Files that failed to process:\n",
      "No failed files. All were successfully processed.\n"
     ]
    }
   ],
   "source": [
    "# First, let's see what files we started with\n",
    "print(f\"Total PDFs found: {len(pdf_files)}\")\n",
    "print(f\"PDF files: {', '.join(pdf_files)}\")\n",
    "\n",
    "# After processing, let's see what made it into documents\n",
    "doc_sources = set(doc.metadata['source'] for doc in documents)\n",
    "print(f\"\\nSuccessfully processed documents: {len(doc_sources)}\")\n",
    "print(f\"Sources: {', '.join(doc_sources)}\")\n",
    "\n",
    "# After chunking, let's see what we have\n",
    "chunk_sources = set(chunk.metadata['source'] for chunk in chunks)\n",
    "print(f\"\\nDocuments that were chunked: {len(chunk_sources)}\")\n",
    "print(f\"Chunked sources: {', '.join(chunk_sources)}\")\n",
    "\n",
    "# Create sets of files\n",
    "original_files = set(pdf_files)\n",
    "processed_files = set(os.path.basename(source) for source in doc_sources)\n",
    "\n",
    "# Find failed files\n",
    "failed_files = original_files - processed_files\n",
    "print(\"\\nFiles that failed to process:\")\n",
    "if not failed_files:  # This checks if the set is empty\n",
    "    print(\"No failed files. All were successfully processed.\")\n",
    "else:\n",
    "    for file in failed_files:\n",
    "        print(f\"- {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f7d2a6-ccfa-425b-a1c3-5e55b23bd013",
   "metadata": {},
   "source": [
    "### Here each chunk of text is mapped into a vector that represents the meaning of the text. This is known as an embedding, and OpenAI's embedding method will be used. The vectors will be stored in a vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78998399-ac17-4e28-b15f-0b5f51e6ee23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 584/584 [17:38<00:00,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "# Put the chunks of data into a Vector Store that associates a Vector Embedding with each chunk\n",
    "# Chroma is a popular open source Vector Database based on SQLLite\n",
    "\n",
    "from tqdm import tqdm  # for progress bar\n",
    "\n",
    "def create_vectorstore_in_batches(chunks, embedding, batch_size=100, db_name=\"db\"):\n",
    "    total_batches = (len(chunks) + batch_size - 1) // batch_size  # Calculate total number of batches\n",
    "    \n",
    "    # Initialize the vector store with the first batch\n",
    "    first_batch = chunks[:batch_size]\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=first_batch,\n",
    "        embedding=embedding,\n",
    "        persist_directory=db_name,\n",
    "        collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "    \n",
    "    # Process the remaining chunks in batches\n",
    "    with tqdm(total=total_batches-1, desc=\"Processing batches\", ncols=150) as pbar:\n",
    "        for i in range(batch_size, len(chunks), batch_size):\n",
    "            batch = chunks[i:i + batch_size]\n",
    "            vectorstore.add_documents(documents=batch)\n",
    "            pbar.update(1)\n",
    "    \n",
    "    return vectorstore\n",
    "\n",
    "# Use it like this:\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vectorstore = create_vectorstore_in_batches(chunks, embeddings, batch_size=100, db_name=db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cdd0f2-aa03-4b94-8fa1-8baa730fed01",
   "metadata": {},
   "source": [
    "### Chroma creates collections in the vector database the holds information, such as the embeddings (vectors), associated metadata, documents/text, and IDs for each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff2e7687-60d4-4920-a1d7-a34b9f70a250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 175,491 vectors with 3,072 dimensions in the vector store\n"
     ]
    }
   ],
   "source": [
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9468860b-86a2-41df-af01-b2400cc985be",
   "metadata": {},
   "source": [
    "## Create the chat model using OpenAI or a local open-source model. Create the retriever and conversation chain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "129c7d1e-0094-4479-9459-f9360b95f244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5q/md8cxlzx0bg2nqrnyc4q_b_w0000gn/T/ipykernel_71790/3145502156.py:8: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "# create a new Chat with OpenAI\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "# Alternative - if you'd like to use Ollama locally, uncomment this line instead\n",
    "#llm = ChatOpenAI(temperature=0.7, model_name='llama3.3', base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "# set up the conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\":5})\n",
    "\n",
    "# putting it together: set up the conversation chain with the GPT 3.5 LLM, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a41c96c-5595-46d6-8f3b-adde4738efbc",
   "metadata": {},
   "source": [
    "### Check to see if the answer to a query is inconclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a06eb84-27e9-43e3-bc25-1b77bfca5f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_inconclusive_answer(answer):\n",
    "    \"\"\"Check if the answer is inconclusive or indicates lack of knowledge.\"\"\"\n",
    "    low_confidence_phrases = [\n",
    "        \"i don't know\", \n",
    "        \"i don't have\", \n",
    "        \"i cannot\", \n",
    "        \"i can't provide\", \n",
    "        \"i do not have\", \n",
    "        \"unable to find\", \n",
    "        \"no information\",\n",
    "        \"not mentioned\",\n",
    "        \"cannot determine\",\n",
    "        \"doesn't mention\",\n",
    "        \"does not mention\",\n",
    "        \"no specific information\",\n",
    "        \"no data\",\n",
    "        \"insufficient information\"\n",
    "    ]\n",
    "    \n",
    "    answer_lower = answer.lower()\n",
    "    return any(phrase in answer_lower for phrase in low_confidence_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4521bb61-ea4a-4f67-95f2-9fd1f27a9686",
   "metadata": {},
   "source": [
    "### Run a quick test with a simple query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "968e7bf2-e862-4679-a11f-6c1efb6ec8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "For a breast cancer patient who has failed fulvestrant, suitable options for next-line therapy may include a CDK 4/6 inhibitor (such as palbociclib, ribociclib, or abemaciclib) in combination with another hormone therapy, or for those with tumor PIK3CA mutations, fulvestrant with alpelisib. Additionally, everolimus can be considered in combination with either an aromatase inhibitor (AI), tamoxifen, or fulvestrant. Monotherapy with fulvestrant could also be an option. It is important to consult with a healthcare provider for personalized treatment recommendations."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "# Let's try a simple question\n",
    "\n",
    "query = \"If a breast cancer patient fails fulvestrant, what would be suitable options for next-line therapy?\"\n",
    "result = conversation_chain.invoke({\"question\": query})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbcb659-13ce-47ab-8a5e-01b930494964",
   "metadata": {},
   "source": [
    "### Create a chat function. If the answer is not in the NCCN guidelines, we will acknowledge this and search the Internet as a fallback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3536590-85c7-4155-bd87-ae78a1467670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question, history):\n",
    "    # First try getting answer from RAG system\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    answer = result[\"answer\"]\n",
    "    \n",
    "    # If the answer seems inconclusive, try DuckDuckGo\n",
    "    if is_inconclusive_answer(answer):\n",
    "        try:\n",
    "            # Initialize DuckDuckGo search\n",
    "            search = DuckDuckGoSearchRun()\n",
    "            \n",
    "            # Perform the search\n",
    "            search_results = search.run(question)\n",
    "            \n",
    "            # Use the LLM to formulate an answer based on search results\n",
    "            enhanced_prompt = f\"\"\"\n",
    "            The original question was: {question}\n",
    "            \n",
    "            Based on the available medical documents, I couldn't find a conclusive answer.\n",
    "            However, I found the following information from a web search:\n",
    "            \n",
    "            {search_results}\n",
    "            \n",
    "            Please provide a helpful response based on this information. \n",
    "            Start your response with \"The answer to the query could not be found in the NCCN guidelines. But based on web search results:\" to clearly indicate this information comes from outside the NCCN guidelines.\n",
    "            \"\"\"\n",
    "            \n",
    "            enhanced_result = llm.invoke(enhanced_prompt)\n",
    "            \n",
    "            # Add search results to memory to maintain conversation context\n",
    "            memory.chat_memory.add_user_message(question)\n",
    "            memory.chat_memory.add_ai_message(enhanced_result.content)\n",
    "            \n",
    "            return enhanced_result.content\n",
    "        except Exception as e:\n",
    "            # If search fails, return the original answer with a note\n",
    "            return f\"{answer}\\n\\nNote: I tried to search for additional information online, but encountered an error: {str(e)}\"\n",
    "    \n",
    "    # If the answer is conclusive, just return it\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257a11e2-a4ca-44fc-bc2e-2165547b67ec",
   "metadata": {},
   "source": [
    "### Use Gradio for a chat user interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b252d8c1-61a8-406d-b57a-8f708a62b014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view = gr.ChatInterface(chat, \n",
    "    type=\"messages\",\n",
    "    css=\"\"\"textarea {\n",
    "        font-size: 18px !important;\n",
    "    }\n",
    "    .message-wrap textarea {\n",
    "        font-size: 18px !important;\n",
    "    }\n",
    "    .message-content {\n",
    "        font-size: 18px !important;\n",
    "    }\n",
    "    .chatbot.prose {\n",
    "        font-size: 18px !important;\n",
    "    }\n",
    "    .svelte-7ddecg {\n",
    "        font-size 18px !important;\n",
    "    }\n",
    "    \"\"\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d582733-63ad-4306-89d4-7a877b07cde1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
